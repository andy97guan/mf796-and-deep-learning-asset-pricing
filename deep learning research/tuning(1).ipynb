{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Seed value\n",
    "# # Apparently you may use different seed values at each stage\n",
    "# seed_value= 0\n",
    "\n",
    "# # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "# import os\n",
    "# os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "# import random\n",
    "# random.seed(seed_value)\n",
    "\n",
    "# # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "# import numpy as np\n",
    "# np.random.seed(seed_value)\n",
    "\n",
    "# # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "# import tensorflow as tf\n",
    "# tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.core import Lambda\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_units = 4\n",
    "SGD_units = 32\n",
    "\n",
    "LSTM_units2 = 8\n",
    "n_g = 8\n",
    "\n",
    "dropout = 0.2\n",
    "\n",
    "epoch = 200\n",
    "batch_size = 200\n",
    "n_iteration = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 32 4 8\n",
      "WARNING:tensorflow:From E:\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:247: RuntimeWarning: overflow encountered in exp\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:270: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a7c43e82c6e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# SDF nets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mhistory_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_g\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m             \u001b[0mfunction_sgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_output_sgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0msdf_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msdf_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mhistory_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# save loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    182\u001b[0m                         \u001b[1;31m# Do not slice the training phase flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                         ins_batch = slice_arrays(\n\u001b[1;32m--> 184\u001b[1;33m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[0m\u001b[0;32m    185\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file = open('a1','rb')\n",
    "dataset = pickle.load(file, encoding='utf-8')\n",
    "file.close()\n",
    "\n",
    "macro_data, micro_data, return_data = dataset\n",
    "# print(macro_data.shape, micro_data.shape, return_data.shape)\n",
    "# print(list(map(type, dataset)))\n",
    "\n",
    "# dataset split\n",
    "train_micro = micro_data[:2000, :, :]\n",
    "train_macro = macro_data[:2000, :, :]\n",
    "train_return = return_data[1:2001, :]\n",
    "train_micro = (train_micro - train_micro.mean(axis=1).reshape(-1, 1, train_micro.shape[2]))/train_micro.std(axis=1).reshape(-1, 1, train_micro.shape[2])\n",
    "\n",
    "\n",
    "validation_micro = micro_data[2001:2600, :, :]\n",
    "validation_macro = macro_data[2001:2600, :, :]\n",
    "validation_return = return_data[2002:2601, :]\n",
    "validation_micro = (validation_micro - validation_micro.mean(axis=1).reshape(-1, 1, validation_micro.shape[2]))/validation_micro.std(axis=1).reshape(-1, 1, validation_micro.shape[2])\n",
    "\n",
    "\n",
    "test_micro = micro_data[2601:-1, :, :]\n",
    "test_macro = macro_data[2601:-1, :, :]\n",
    "test_return = return_data[2602:, :]\n",
    "test_micro = (test_micro - test_micro.mean(axis=1).reshape(-1, 1, test_micro.shape[2]))/\\\n",
    "test_micro.std(axis=1).reshape(-1, 1, test_micro.shape[2])\n",
    "\n",
    "\n",
    "# model parameter\n",
    "ndays = train_micro.shape[0]\n",
    "nstocks = train_micro.shape[1]\n",
    "nmacro = train_macro.shape[2]\n",
    "nmicro = train_micro.shape[2]\n",
    "LSTM_delay = train_macro.shape[1]\n",
    "\n",
    "param_list = [\n",
    "#     [4,32,8,8],\n",
    "#     [4,32,8,8],\n",
    "#     [4,32,8,4],\n",
    "#     [4,32,4,8],\n",
    "#     [4,32,4,4],\n",
    "#     [4,64,8,8],\n",
    "#     [4,64,4,4],\n",
    "#     [4,64,4,8],\n",
    "#     [4,64,8,4], \n",
    "    [8,32,4,8],\n",
    "    [8,32,8,4],\n",
    "    [8,32,4,8],\n",
    "    [8,32,4,4],\n",
    "    [8,64,8,8],\n",
    "    [8,64,8,4],\n",
    "    [8,64,4,8],\n",
    "    [8,64,4,4],   \n",
    "]\n",
    "\n",
    "for [LSTM_units, SGD_units, LSTM_units2, n_g] in param_list:\n",
    "    print(LSTM_units, SGD_units, LSTM_units2, n_g)\n",
    "\n",
    "    result = pd.DataFrame([[0,0,0,0, 0, 0, 0] for i in range(3)], columns = ['mean','std','shape','SR','bench_mean','bench_std','bench_SR'], index=['train','validation','test'])\n",
    "    t1 = time.time()\n",
    "    for j in range(20):\n",
    "\n",
    "        # SGD networks\n",
    "\n",
    "        # data loading\n",
    "        ma1 = Input(shape=(LSTM_delay, nmacro), name='macro')\n",
    "\n",
    "        mi1 = Input(shape=(nstocks,nmicro), name='micro')\n",
    "\n",
    "        ret1 = Input(shape=(nstocks,), name='return')\n",
    "\n",
    "        g_loaded = Input(shape=(nstocks, n_g), name='function_G')\n",
    "\n",
    "        # LSTM\n",
    "        lstm1_1 = LSTM(LSTM_units, name='lstm')(ma1) # (1000, 4)\n",
    "        lstm1 = Lambda(lambda x:K.repeat(x, nstocks), name='lstm_reshape')(lstm1_1)\n",
    "\n",
    "\n",
    "        # SGD weights DNN\n",
    "        w1 = concatenate([mi1, lstm1], name='micro_macro_combined') # (1000, 50, 104)  \n",
    "        w2 = Lambda(lambda x:K.reshape(x, shape=(-1,nstocks*(nmicro+LSTM_units),)), name='ffn_input_reshape')(w1)\n",
    "        w3 = Dense(SGD_units, activation='relu', name='ffn_layer1')(w2)\n",
    "        w4 = Dropout(dropout, name='ffn_dropout1')(w3)\n",
    "        w5 = Dense(SGD_units, activation='relu', name='ffn_layer2')(w4)\n",
    "        w6 = Dropout(dropout, name='ffn_dropout2')(w5)\n",
    "        # w = Dense(50, name='ffn_output_weights',activation='tanh')(w6)\n",
    "        w = Dense(nstocks, name='ffn_output_weights')(w6)\n",
    "\n",
    "\n",
    "        # SGD construction\n",
    "        def construction(x):\n",
    "            tmp = 1 - x[0] * x[1]\n",
    "            tmp = K.sum(tmp, axis=1)\n",
    "            tmp = K.reshape(tmp, shape=(-1,1)) # (1000, 1)\n",
    "            tmp = K.repeat(tmp, nstocks) # (1000, 50, 1)\n",
    "            tmp = K.reshape(tmp, shape=(-1,nstocks)) # (1000, 50)\n",
    "            tmp = tmp * x[1] # (1000, 50)\n",
    "            tmp = K.reshape(tmp, shape=(-1, nstocks, 1))\n",
    "            return tmp # the M_{t+1}R_{t+1}\n",
    "\n",
    "        sgd = Lambda(construction, name='sgd')([w,ret1])\n",
    "\n",
    "\n",
    "        # combine those two and calculate loss\n",
    "        loss_function_w1 = Lambda(lambda x:x[0]*x[1], name='loss')([sgd, g_loaded]) \n",
    "        loss_function_w = Lambda(lambda x:K.reshape(x, shape=(-1, nstocks*n_g)), name='loss_reshape')(loss_function_w1)\n",
    "\n",
    "\n",
    "        def mean_squared_error1(y_true, y_pred):\n",
    "            return K.mean(K.square(K.mean(y_pred-y_true,axis=0)))\n",
    "        #     return K.mean(K.square(y_pred-y_true))\n",
    "\n",
    "        # with weights output for validation and sgd output for condition network training\n",
    "        model_output_w = Model(inputs=[ma1, mi1], outputs=w) # acquires weights given info\n",
    "        model_output_sgd = Model(inputs=[ma1, mi1, ret1], outputs=sgd) # acquires MR for condition networks\n",
    "\n",
    "        model_output_sgd.compile(optimizer='adam', loss=mean_squared_error1)\n",
    "\n",
    "        # SGD model compile\n",
    "        model_w = Model(inputs=[ma1, mi1, ret1, g_loaded], outputs=loss_function_w)\n",
    "        model_w.compile(optimizer='adam', loss=mean_squared_error1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # conditional networks\n",
    "\n",
    "        ma2 = Input(shape=(LSTM_delay, nmacro), name='macro')\n",
    "\n",
    "        mi2 = Input(shape=(nstocks,nmicro), name='micro')\n",
    "\n",
    "        sgd_loaded = Input(shape=(nstocks,1), name='sgd')\n",
    "\n",
    "        lstm2_1 = LSTM(LSTM_units2, name='lstm')(ma2) # (1000, 4)\n",
    "        lstm2 = Lambda(lambda x:K.repeat(x, nstocks), name='lstm_reshape')(lstm2_1)\n",
    "\n",
    "        g0 = concatenate([mi2, lstm2], name='g0') # (1000, 50, 104) \n",
    "        g1 = Lambda(lambda x:K.reshape(x, shape=(-1,nstocks*(nmicro+LSTM_units2),)), name='g1')(g0)\n",
    "        # cons = MaxNorm(max_value=0.001, axis=0)\n",
    "        # g2 = Dense(128, activation='relu',kernel_constraint=cons, bias_constraint=cons, name='g2')(g1)\n",
    "        g3 = Dropout(dropout, name='g3')(g1) # (1000, 50, 8)\n",
    "        g4 = Dense(nstocks*n_g, name='g4')(g3) # (1000, 50, 8)\n",
    "        g5 = Lambda(lambda x:K.reshape(x, shape=(-1,nstocks,n_g)), name='g5')(g4)\n",
    "        g = Lambda(lambda x:(x-K.reshape(K.mean(x, axis=-1), (-1,nstocks,1)))/K.reshape(K.std(x, axis=-1), (-1,nstocks,1)), name='g')(g5)\n",
    "\n",
    "        loss_function_g1 = Lambda(lambda x:x[0]*x[1], name='loss')([sgd_loaded, g]) # (1000,50, 8)\n",
    "        loss_function_g = Lambda(lambda x:K.reshape(x, shape=(-1, nstocks*n_g)), name='loss_reshape')(loss_function_g1)\n",
    "\n",
    "        model_output_g = Model(inputs=[ma2, mi2], outputs=g) # acquires MR for condition networks\n",
    "\n",
    "        def mean_squared_error2(y_true, y_pred):\n",
    "            return -K.mean(K.square(K.mean(y_pred-y_true,axis=0)))\n",
    "        #     return -K.mean(K.square(y_pred-y_true))\n",
    "\n",
    "        model_g = Model(inputs=[ma2, mi2, sgd_loaded], outputs=loss_function_g)\n",
    "        model_g.compile(optimizer='adam', loss=mean_squared_error2)\n",
    "        # model_g.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        def moving_average(x, n):\n",
    "            xx = np.cumsum(x)\n",
    "            xxx = xx.copy()\n",
    "            xxx[n:] = (xx[n:] - xx[:-n]) / n\n",
    "            for i in range(n):\n",
    "                xxx[i] = xxx[i] / (i+1)\n",
    "            return xxx\n",
    "\n",
    "        # data process\n",
    "        y_validation = np.zeros((validation_macro.shape[0], n_g*nstocks))\n",
    "        y_train = np.zeros((ndays, n_g*nstocks))\n",
    "        y_train_unconditional = np.zeros((ndays, nstocks, 1))\n",
    "\n",
    "        ma = train_macro\n",
    "        mi = train_micro\n",
    "        ret = train_return\n",
    "        sdf_loss = []\n",
    "\n",
    "\n",
    "\n",
    "        # first use unconditional methods to give a initial guess of sgd\n",
    "        t1 = time.time()\n",
    "        # SDF nets\n",
    "        history_w = model_output_sgd.fit([ma, mi, ret], y_train_unconditional, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "        function_sgd = model_output_sgd.predict([ma, mi, ret])\n",
    "        sdf_loss = sdf_loss + history_w.history['loss'].copy() # save loss\n",
    "        # print('done with', 0,',train loss is', round(sdf_loss[-1],6) ,', using', round(time.time()-t1, 2), 'seconds')\n",
    "        # plt.plot(moving_average(history_w.history['loss'], 20))\n",
    "        # plt.show()\n",
    "\n",
    "        for i in range(n_iteration):\n",
    "#             t1 = time.time()\n",
    "            # conditional nets\n",
    "            history_w = model_g.fit([ma, mi, function_sgd], y_train, epochs=epoch,  batch_size=batch_size, verbose=0)\n",
    "            function_g = model_output_g.predict([ma, mi])\n",
    "        #     print('done with conditional', i, 'loss is',round(history_w.history['loss'][-1],6),'using', round(time.time()-t1, 2), 'seconds')\n",
    "        #     plt.plot(moving_average(history_w.history['loss'], 20))\n",
    "        #     plt.show()\n",
    "\n",
    "            t1 = time.time()\n",
    "            # SDF nets\n",
    "            history_w = model_w.fit([ma, mi, ret, function_g], y_train, epochs=epoch, batch_size=batch_size,  verbose=0)\n",
    "            function_sgd = model_output_sgd.predict([ma, mi, ret])\n",
    "            sdf_loss = sdf_loss + history_w.history['loss'].copy() # save loss\n",
    "            validation_loss = np.mean((model_w.predict([validation_macro, validation_micro, validation_return, function_g]) - y_validation)**2)\n",
    "        #     print('done with sgd', i,',train loss is', round(sdf_loss[-1],6), ',validation loss is',round(validation_loss,6), ', using', round(time.time()-t1, 2), 'seconds')\n",
    "        #     plt.plot(moving_average(history_w.history['loss'], 20))\n",
    "        #     plt.show()\n",
    "            print(i)\n",
    "\n",
    "        # plt.figure(figsize=(20,6))\n",
    "        # plt.plot(moving_average(sdf_loss[:], 20))\n",
    "        # plt.title('loss function of SGD nets')\n",
    "        # plt.grid()\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "        # training set condition\n",
    "        train_weights = model_output_w.predict([train_macro[:,:], train_micro[:, :, :]])\n",
    "        # train_weights = (train_weights - train_weights.mean(axis=1).reshape(-1,1)) / train_weights.std(axis=1).reshape(-1,1)\n",
    "        train_weights = 1/(1+np.exp(-train_weights)) \n",
    "        # train_yield = train_weights\n",
    "        train_daily_return = (train_weights/train_weights.sum(axis=1).reshape(-1,1) * train_return).sum(axis=1)\n",
    "        result.iloc[0, 0] += train_daily_return.mean()*252\n",
    "        result.iloc[0, 1] += train_daily_return.std() * np.sqrt(252)\n",
    "        result.iloc[0, 2] += train_daily_return.shape\n",
    "\n",
    "    #     fig = plt.figure(figsize=(20,20))\n",
    "    #     ax1 = fig.add_subplot(311)\n",
    "        benchmark = train_return.mean(axis=1)\n",
    "    #     ax1.plot(np.cumprod(1+train_daily_return), color='red',label='sdf')\n",
    "    #     ax1.plot(np.cumprod(1+benchmark), color='blue',label='benchmark')\n",
    "    #     plt.legend()\n",
    "    #     plt.title('training set backtest')\n",
    "    #     plt.grid()\n",
    "\n",
    "        result.iloc[0, 3] += train_daily_return.mean()/train_daily_return.std()*np.sqrt(252)\n",
    "        result.iloc[0, 4] += benchmark.mean()*252\n",
    "        result.iloc[0, 5] += benchmark.std()*np.sqrt(252)\n",
    "        result.iloc[0, 6] += benchmark.mean()/benchmark.std()*np.sqrt(252)\n",
    "\n",
    "\n",
    "        # training set condition\n",
    "        validation_weights = model_output_w.predict([validation_macro[:,:], validation_micro[:, :, :]])\n",
    "        # validation_weights = (validation_weights - validation_weights.mean(axis=1).reshape(-1,1)) / validation_weights.std(axis=1).reshape(-1,1)\n",
    "        validation_weights = 1/(1+np.exp(-validation_weights))\n",
    "        # train_yield = train_weights\n",
    "        validation_daily_return = (validation_weights/validation_weights.sum(axis=1).reshape(-1,1) * validation_return).sum(axis=1)\n",
    "        result.iloc[1, 0] += validation_daily_return.mean()*252\n",
    "        result.iloc[1, 1] += validation_daily_return.std() * np.sqrt(252)\n",
    "        result.iloc[1, 2] += validation_daily_return.shape\n",
    "\n",
    "        benchmark = validation_return.mean(axis=1)\n",
    "    #     ax2 = fig.add_subplot(312)\n",
    "    #     ax2.plot(np.cumprod(1+validation_daily_return), color='red',label='sdf')\n",
    "    #     ax2.plot(np.cumprod(1+benchmark), color='blue',label='benchmark')\n",
    "    #     plt.legend()\n",
    "    #     plt.grid()\n",
    "    #     plt.title('validation set backtest')\n",
    "\n",
    "        result.iloc[1, 3] += validation_daily_return.mean()/validation_daily_return.std()*np.sqrt(252)\n",
    "        result.iloc[1, 4] += benchmark.mean()*252\n",
    "        result.iloc[1, 5] += benchmark.std()*np.sqrt(252)\n",
    "        result.iloc[1, 6] += benchmark.mean()/benchmark.std()*np.sqrt(252)\n",
    "\n",
    "        # # training set condition\n",
    "        test_weights = model_output_w.predict([test_macro[:,:], test_micro[:, :, :]])\n",
    "        # test_weights = (test_weights - test_weights.mean(axis=1).reshape(-1,1)) / test_weights.std(axis=1).reshape(-1,1)\n",
    "        test_weights = 1/(1+np.exp(-test_weights))\n",
    "        # train_yield = train_weights\n",
    "        test_daily_return = (test_weights/test_weights.sum(axis=1).reshape(-1,1) * test_return).sum(axis=1)\n",
    "        result.iloc[2, 0] += test_daily_return.mean()*252\n",
    "        result.iloc[2, 1] += test_daily_return.std() * np.sqrt(252)\n",
    "        result.iloc[2, 2] += test_daily_return.shape\n",
    "\n",
    "        benchmark = test_return.mean(axis=1)\n",
    "    #     ax2 = fig.add_subplot(313)\n",
    "    #     plt.plot(np.cumprod(1+test_daily_return), color='red',label='sdf')\n",
    "    #     plt.plot(np.cumprod(1+benchmark), color='blue',label='benchmark')\n",
    "    #     plt.legend()  \n",
    "    #     plt.grid()\n",
    "    #     plt.title('test set backtest')\n",
    "\n",
    "        result.iloc[2, 3] += test_daily_return.mean()/test_daily_return.std()*np.sqrt(252)\n",
    "        result.iloc[2, 4] += benchmark.mean()*252\n",
    "        result.iloc[2, 5] += benchmark.std()*np.sqrt(252)\n",
    "        result.iloc[2, 6] += benchmark.mean()/benchmark.std()*np.sqrt(252)\n",
    "        print(j, end=' ')\n",
    "    \n",
    "    print()\n",
    "    result = result / 20\n",
    "    # plt.show()\n",
    "    print(result)\n",
    "    print('using', time.time()-t1, 'seconds')\n",
    "    print('====================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
