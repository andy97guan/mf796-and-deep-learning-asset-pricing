{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.core import Lambda\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3233, 13, 15) (3233, 50, 30) (3233, 50)\n",
      "[<class 'numpy.ndarray'>, <class 'numpy.ndarray'>, <class 'numpy.ndarray'>]\n"
     ]
    }
   ],
   "source": [
    "file = open('a1','rb')\n",
    "dataset = pickle.load(file, encoding='utf-8')\n",
    "file.close()\n",
    "\n",
    "macro_data, micro_data, return_data = dataset\n",
    "print(macro_data.shape, micro_data.shape, return_data.shape)\n",
    "print(list(map(type, dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset split\n",
    "train_micro = micro_data[:2000, :, :]\n",
    "train_macro = macro_data[:2000, :, :]\n",
    "train_return = return_data[1:2001, :]\n",
    "\n",
    "validation_micro = micro_data[2001:2600, :, :]\n",
    "validation_macro = macro_data[2001:2600, :, :]\n",
    "validation_return = return_data[2002:2601, :]\n",
    "\n",
    "test_micro = micro_data[2601:-1, :, :]\n",
    "test_macro = macro_data[2601:-1, :, :]\n",
    "test_return = return_data[2602:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameter\n",
    "ndays = train_micro.shape[0]\n",
    "nstocks = train_micro.shape[1]\n",
    "nmacro = train_macro.shape[2]\n",
    "nmicro = train_micro.shape[2]\n",
    "LSTM_delay = train_macro.shape[1]\n",
    "n_g = 4\n",
    "LSTM_units = 4\n",
    "LSTM_units2 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD networks\n",
    "\n",
    "# data loading\n",
    "ma1 = Input(shape=(LSTM_delay, nmacro), name='macro')\n",
    "\n",
    "mi1 = Input(shape=(nstocks,nmicro), name='micro')\n",
    "\n",
    "ret1 = Input(shape=(nstocks,), name='return')\n",
    "\n",
    "g_loaded = Input(shape=(nstocks, n_g), name='function_G')\n",
    "\n",
    "# LSTM\n",
    "lstm1_1 = LSTM(LSTM_units, name='lstm')(ma1) # (1000, 4)\n",
    "lstm1 = Lambda(lambda x:K.repeat(x, nstocks), name='lstm_reshape')(lstm1_1)\n",
    "\n",
    "\n",
    "# SGD weights DNN\n",
    "w1 = concatenate([mi1, lstm1], name='micro_macro_combined') # (1000, 50, 104)  \n",
    "w2 = Lambda(lambda x:K.reshape(x, shape=(-1,nstocks*(nmicro+LSTM_units),)), name='ffn_input_reshape')(w1)\n",
    "w3 = Dense(128, activation='relu', name='ffn_layer1')(w2)\n",
    "w4 = Dropout(0.2, name='ffn_dropout1')(w3)\n",
    "w5 = Dense(128, activation='relu', name='ffn_layer2')(w4)\n",
    "w6 = Dropout(0.2, name='ffn_dropout2')(w5)\n",
    "# w = Dense(50, name='ffn_output_weights',activation='tanh')(w6)\n",
    "w = Dense(50, name='ffn_output_weights')(w6)\n",
    "\n",
    "\n",
    "# SGD construction\n",
    "def construction(x):\n",
    "    tmp = 1 - x[0] * x[1]\n",
    "    tmp = K.sum(tmp, axis=1)\n",
    "    tmp = K.reshape(tmp, shape=(-1,1)) # (1000, 1)\n",
    "    tmp = K.repeat(tmp, nstocks) # (1000, 50, 1)\n",
    "    tmp = K.reshape(tmp, shape=(-1,nstocks)) # (1000, 50)\n",
    "    tmp = tmp * x[1] # (1000, 50)\n",
    "    tmp = K.reshape(tmp, shape=(-1, nstocks, 1))\n",
    "    return tmp # the M_{t+1}R_{t+1}\n",
    "\n",
    "sgd = Lambda(construction, name='sgd')([w,ret1])\n",
    "\n",
    "\n",
    "# combine those two and calculate loss\n",
    "loss_function_w1 = Lambda(lambda x:x[0]*x[1], name='loss')([sgd, g_loaded]) \n",
    "loss_function_w = Lambda(lambda x:K.reshape(x, shape=(-1, nstocks*n_g)), name='loss_reshape')(loss_function_w1)\n",
    "\n",
    "\n",
    "def mean_squared_error1(y_true, y_pred):\n",
    "    return K.mean(K.square(K.mean(y_pred-y_true,axis=0)))\n",
    "#     return K.mean(K.square(y_pred-y_true))\n",
    "\n",
    "# with weights output for validation and sgd output for condition network training\n",
    "model_output_w = Model(inputs=[ma1, mi1], outputs=w) # acquires weights given info\n",
    "model_output_sgd = Model(inputs=[ma1, mi1, ret1], outputs=sgd) # acquires MR for condition networks\n",
    "\n",
    "model_output_sgd.compile(optimizer='adam', loss=mean_squared_error1)\n",
    "\n",
    "# SGD model compile\n",
    "model_w = Model(inputs=[ma1, mi1, ret1, g_loaded], outputs=loss_function_w)\n",
    "model_w.compile(optimizer='adam', loss=mean_squared_error1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "macro (InputLayer)              (None, 13, 15)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 4)            320         macro[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "micro (InputLayer)              (None, 50, 30)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_reshape (Lambda)           (None, 50, 4)        0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "micro_macro_combined (Concatena (None, 50, 34)       0           micro[0][0]                      \n",
      "                                                                 lstm_reshape[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ffn_input_reshape (Lambda)      (None, 1700)         0           micro_macro_combined[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ffn_layer1 (Dense)              (None, 128)          217728      ffn_input_reshape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ffn_dropout1 (Dropout)          (None, 128)          0           ffn_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ffn_layer2 (Dense)              (None, 128)          16512       ffn_dropout1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ffn_dropout2 (Dropout)          (None, 128)          0           ffn_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ffn_output_weights (Dense)      (None, 50)           6450        ffn_dropout2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "return (InputLayer)             (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sgd (Lambda)                    (None, 50, 1)        0           ffn_output_weights[0][0]         \n",
      "                                                                 return[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "function_G (InputLayer)         (None, 50, 4)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "loss (Lambda)                   (None, 50, 4)        0           sgd[0][0]                        \n",
      "                                                                 function_G[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "loss_reshape (Lambda)           (None, 200)          0           loss[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 241,010\n",
      "Trainable params: 241,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_w.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional networks\n",
    "\n",
    "ma2 = Input(shape=(LSTM_delay, nmacro), name='macro')\n",
    "\n",
    "mi2 = Input(shape=(nstocks,nmicro), name='micro')\n",
    "\n",
    "sgd_loaded = Input(shape=(nstocks,1), name='sgd')\n",
    "\n",
    "lstm2_1 = LSTM(LSTM_units2, name='lstm')(ma2) # (1000, 4)\n",
    "lstm2 = Lambda(lambda x:K.repeat(x, nstocks), name='lstm_reshape')(lstm2_1)\n",
    "\n",
    "g0 = concatenate([mi2, lstm2], name='g0') # (1000, 50, 104) \n",
    "g1 = Lambda(lambda x:K.reshape(x, shape=(-1,nstocks*(nmicro+LSTM_units),)), name='g1')(g0)\n",
    "# cons = MaxNorm(max_value=0.001, axis=0)\n",
    "# g2 = Dense(128, activation='relu',kernel_constraint=cons, bias_constraint=cons, name='g2')(g1)\n",
    "g3 = Dropout(0.2, name='g3')(g1) # (1000, 50, 8)\n",
    "g4 = Dense(nstocks*n_g, name='g4')(g3) # (1000, 50, 8)\n",
    "g5 = Lambda(lambda x:K.reshape(x, shape=(-1,nstocks,n_g)), name='g5')(g4)\n",
    "g = Lambda(lambda x:(x-K.reshape(K.mean(x, axis=-1), (-1,nstocks,1)))/K.reshape(K.std(x, axis=-1), (-1,nstocks,1)), name='g')(g5)\n",
    "\n",
    "loss_function_g1 = Lambda(lambda x:x[0]*x[1], name='loss')([sgd_loaded, g]) # (1000,50, 8)\n",
    "loss_function_g = Lambda(lambda x:K.reshape(x, shape=(-1, nstocks*n_g)), name='loss_reshape')(loss_function_g1)\n",
    "\n",
    "model_output_g = Model(inputs=[ma2, mi2], outputs=g) # acquires MR for condition networks\n",
    "\n",
    "def mean_squared_error2(y_true, y_pred):\n",
    "    return -K.mean(K.square(K.mean(y_pred-y_true,axis=0)))\n",
    "#     return -K.mean(K.square(y_pred-y_true))\n",
    "\n",
    "model_g = Model(inputs=[ma2, mi2, sgd_loaded], outputs=loss_function_g)\n",
    "model_g.compile(optimizer='adam', loss=mean_squared_error2)\n",
    "# model_g.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "macro (InputLayer)              (None, 13, 15)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 4)            320         macro[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "micro (InputLayer)              (None, 50, 30)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_reshape (Lambda)           (None, 50, 4)        0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "g0 (Concatenate)                (None, 50, 34)       0           micro[0][0]                      \n",
      "                                                                 lstm_reshape[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "g1 (Lambda)                     (None, 1700)         0           g0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "g3 (Dropout)                    (None, 1700)         0           g1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "g4 (Dense)                      (None, 200)          340200      g3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "g5 (Lambda)                     (None, 50, 4)        0           g4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "sgd (InputLayer)                (None, 50, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "g (Lambda)                      (None, 50, 4)        0           g5[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "loss (Lambda)                   (None, 50, 4)        0           sgd[0][0]                        \n",
      "                                                                 g[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "loss_reshape (Lambda)           (None, 200)          0           loss[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 340,520\n",
      "Trainable params: 340,520\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, n):\n",
    "    xx = np.cumsum(x)\n",
    "    xxx = xx.copy()\n",
    "    xxx[n:] = (xx[n:] - xx[:-n]) / n\n",
    "    for i in range(n):\n",
    "        xxx[i] = xxx[i] / (i+1)\n",
    "    return xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 200)\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "done with 0 ,train loss is 161659921612.8 , using 23.42 seconds\n",
      "done with conditional 0 loss is -147005892198.4 using 35.44 seconds\n",
      "done with sgd 0 ,train loss is 1253528768.0 ,validation loss is 14257126947711.777 , using 31.57 seconds\n"
     ]
    }
   ],
   "source": [
    "# data process\n",
    "y_validation = np.zeros((validation_macro.shape[0], n_g*nstocks))\n",
    "y_train = np.zeros((ndays, n_g*nstocks))\n",
    "y_train_unconditional = np.zeros((ndays, nstocks, 1))\n",
    "\n",
    "print(y_train.shape)\n",
    "ma = train_macro\n",
    "mi = train_micro\n",
    "ret = train_return\n",
    "sdf_loss = []\n",
    "\n",
    "epoch = 200\n",
    "batch_size = 200\n",
    "n_iteration = 500\n",
    "\n",
    "# first use unconditional methods to give a initial guess of sgd\n",
    "t1 = time.time()\n",
    "# SDF nets\n",
    "history_w = model_output_sgd.fit([ma, mi, ret], y_train_unconditional, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "function_sgd = model_output_sgd.predict([ma, mi, ret])\n",
    "sdf_loss = sdf_loss + history_w.history['loss'].copy() # save loss\n",
    "print('done with', 0,',train loss is', round(sdf_loss[-1],6) ,', using', round(time.time()-t1, 2), 'seconds')\n",
    "# plt.plot(moving_average(history_w.history['loss'], 20))\n",
    "# plt.show()\n",
    "\n",
    "for i in range(100):\n",
    "    t1 = time.time()\n",
    "    # conditional nets\n",
    "    history_w = model_g.fit([ma, mi, function_sgd], y_train, epochs=epoch,  batch_size=batch_size, verbose=0)\n",
    "    function_g = model_output_g.predict([ma, mi])\n",
    "    print('done with conditional', i, 'loss is',round(history_w.history['loss'][-1],6),'using', round(time.time()-t1, 2), 'seconds')\n",
    "#     plt.plot(moving_average(history_w.history['loss'], 20))\n",
    "#     plt.show()\n",
    "    \n",
    "    t1 = time.time()\n",
    "    # SDF nets\n",
    "    history_w = model_w.fit([ma, mi, ret, function_g], y_train, epochs=epoch, batch_size=batch_size,  verbose=0)\n",
    "    function_sgd = model_output_sgd.predict([ma, mi, ret])\n",
    "    sdf_loss = sdf_loss + history_w.history['loss'].copy() # save loss\n",
    "    validation_loss = np.mean((model_w.predict([validation_macro, validation_micro, validation_return, function_g]) - y_validation)**2)\n",
    "    print('done with sgd', i,',train loss is', round(sdf_loss[-1],6), ',validation loss is',round(validation_loss,6), ', using', round(time.time()-t1, 2), 'seconds')\n",
    "#     plt.plot(moving_average(history_w.history['loss'], 20))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(moving_average(sdf_loss[2000\n",
    "                                 \n",
    "                                 :], 20))\n",
    "plt.title('loss function of SGD nets')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame([[0,0,0,0, 0, 0, 0] for i in range(3)], columns = ['mean','std','shape','SR','bench_mean','bench_std','bench_SR'], index=['train','validation','test'])\n",
    "\n",
    "# training set condition\n",
    "train_weights = model_output_w.predict([train_macro[:,:], train_micro[:, :, :]])\n",
    "# train_weights = (train_weights - train_weights.mean(axis=1).reshape(-1,1)) / train_weights.std(axis=1).reshape(-1,1)\n",
    "train_weights = 1/(1+np.exp(-train_weights)) \n",
    "# train_yield = train_weights\n",
    "train_daily_return = (train_weights/train_weights.sum(axis=1).reshape(-1,1) * train_return).sum(axis=1)\n",
    "result.iloc[0, 0] = train_daily_return.mean()*252\n",
    "result.iloc[0, 1] = train_daily_return.std() * np.sqrt(252)\n",
    "result.iloc[0, 2] = train_daily_return.shape\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax1 = fig.add_subplot(311)\n",
    "benchmark = train_return.mean(axis=1)\n",
    "ax1.plot(np.cumprod(1+train_daily_return), color='red',label='sdf')\n",
    "ax1.plot(np.cumprod(1+benchmark), color='blue',label='benchmark')\n",
    "plt.legend()\n",
    "plt.title('training set backtest')\n",
    "plt.grid()\n",
    "\n",
    "result.iloc[0, 3] = train_daily_return.mean()/train_daily_return.std()*np.sqrt(252)\n",
    "result.iloc[0, 4] = benchmark.mean()*252\n",
    "result.iloc[0, 5] = benchmark.std()*np.sqrt(252)\n",
    "result.iloc[0, 6] = benchmark.mean()/benchmark.std()*np.sqrt(252)\n",
    "\n",
    "\n",
    "# training set condition\n",
    "validation_weights = model_output_w.predict([validation_macro[:,:], validation_micro[:, :, :]])\n",
    "# validation_weights = (validation_weights - validation_weights.mean(axis=1).reshape(-1,1)) / validation_weights.std(axis=1).reshape(-1,1)\n",
    "validation_weights = 1/(1+np.exp(-validation_weights))\n",
    "# train_yield = train_weights\n",
    "validation_daily_return = (validation_weights/validation_weights.sum(axis=1).reshape(-1,1) * validation_return).sum(axis=1)\n",
    "result.iloc[1, 0] = validation_daily_return.mean()*252\n",
    "result.iloc[1, 1] = validation_daily_return.std() * np.sqrt(252)\n",
    "result.iloc[1, 2] = validation_daily_return.shape\n",
    "\n",
    "benchmark = validation_return.mean(axis=1)\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax2.plot(np.cumprod(1+validation_daily_return), color='red',label='sdf')\n",
    "ax2.plot(np.cumprod(1+benchmark), color='blue',label='benchmark')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('validation set backtest')\n",
    "\n",
    "result.iloc[1, 3] = validation_daily_return.mean()/validation_daily_return.std()*np.sqrt(252)\n",
    "result.iloc[1, 4] = benchmark.mean()*252\n",
    "result.iloc[1, 5] = benchmark.std()*np.sqrt(252)\n",
    "result.iloc[1, 6] = benchmark.mean()/benchmark.std()*np.sqrt(252)\n",
    "\n",
    "# # training set condition\n",
    "# test_weights = model_output_w.predict([test_macro[:,:], test_micro[:, :, :]])\n",
    "# # test_weights = (test_weights - test_weights.mean(axis=1).reshape(-1,1)) / test_weights.std(axis=1).reshape(-1,1)\n",
    "# test_weights = 1/(1+np.exp(-test_weights))\n",
    "# # train_yield = train_weights\n",
    "# test_daily_return = (test_weights/test_weights.sum(axis=1).reshape(-1,1) * test_return).sum(axis=1)\n",
    "# result.iloc[2, 0] = test_daily_return.mean()*252\n",
    "# result.iloc[2, 1] = test_daily_return.std() * np.sqrt(252)\n",
    "# result.iloc[2, 2] = test_daily_return.shape\n",
    "\n",
    "# benchmark = test_return.mean(axis=1)\n",
    "# ax2 = fig.add_subplot(313)\n",
    "# plt.plot(np.cumprod(1+test_daily_return), color='red',label='sdf')\n",
    "# plt.plot(np.cumprod(1+benchmark), color='blue',label='benchmark')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.title('test set backtest')\n",
    "\n",
    "# result.iloc[2, 3] = test_daily_return.mean()/test_daily_return.std()*np.sqrt(252)\n",
    "# result.iloc[2, 4] = benchmark.mean()*252\n",
    "# result.iloc[2, 5] = benchmark.std()*np.sqrt(252)\n",
    "# result.iloc[2, 6] = benchmark.mean()/benchmark.std()*np.sqrt(252)\n",
    "\n",
    "plt.show()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portfolio weights example after balancing\n",
    "(train_weights/train_weights.sum(axis=1).reshape(-1,1)).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## portfolio weights example before balancing\n",
    "model_output_w.predict([train_macro[:,:], train_micro[:, :, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
